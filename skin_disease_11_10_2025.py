# -*- coding: utf-8 -*-
"""SKIN DISEASE 11-10-2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cgFjPUKZ-hfKxQESOf32SlWQcmsO9EzS
"""

# Commented out IPython magic to ensure Python compatibility.
                 from google.colab import drive
drive.mount('/content/drive')
# %cd "/content/drive/MyDrive/SKIN DISEASE"

import os

base_dir = "dataset"
for split in ["train", "val", "test"]:
    os.makedirs(os.path.join(base_dir, split), exist_ok=True)

print(" Dataset folders created:")

!ls dataset
!ls dataset/train
!ls dataset/val
!ls dataset/test

!pip install -q kaggle tensorflow scikit-learn
from google.colab import files

print(" Upload your kaggle.json (from Kaggle account settings) in the dialog…")
files.upload()  # select kaggle.json

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!mv "kaggle (2).json" kaggle.json
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets list

import os

# raw datasets (unzipped sources)
os.makedirs("raw/acne", exist_ok=True)
os.makedirs("raw/chickenpox_measles", exist_ok=True)
os.makedirs("raw/monkeypox", exist_ok=True)
os.makedirs("raw/dermnet", exist_ok=True)

# final dataset (train/val/test)
for split in ["train","val","test"]:
    os.makedirs(f"dataset/{split}", exist_ok=True)

print(" Empty folders created for raw data + final dataset")
!ls

# Acne (separate dataset)
!kaggle datasets download -d nayanchaure/acne-dataset -p raw/acne
!unzip -q raw/acne/acne-dataset.zip -d raw/acne

# Chickenpox + Measles dataset
!kaggle datasets download -d niharika41298/chickenpox-and-measles -p raw/chickenpox_measles
!unzip -q raw/chickenpox_measles/chickenpox-and-measles.zip -d raw/chickenpox_measles

# Monkeypox dataset (also contains Chickenpox in some versions)
!kaggle datasets download -d dipuiucse/monkeypoxskinimagedataset -p raw/monkeypox
!unzip -q raw/monkeypox/monkeypoxskinimagedataset.zip -d raw/monkeypox

# DermNet dataset (contains many diseases → we will extract Eczema, Psoriasis, Tinea, Vitiligo, Pityriasis Rosea)
!kaggle datasets download -d shubhamgoel27/dermnet -p raw/dermnet
!unzip -q raw/dermnet/dermnet.zip -d raw/dermnet

import os, shutil, random

# Valid image extensions
IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".gif", ".webp", ".tif", ".tiff"}

def count_images(dirpath):
    """Count images inside a folder"""
    if not os.path.isdir(dirpath):
        return 0
    return len([f for f in os.listdir(dirpath) if os.path.splitext(f)[1].lower() in IMG_EXTS])

def find_dir_by_keywords(root, keywords):
    """
    Search inside a root folder for a subfolder whose name contains all given keywords.
    Example: find_dir_by_keywords("/content/raw", ["eczema"])
    """
    kws = [k.lower() for k in keywords]
    for cur, dirs, files in os.walk(root):
        if all(k in cur.lower() for k in kws) and count_images(cur) > 5:
            return cur
    return None

def prepare_dataset(source_dir, class_name, base_dir="dataset", split_ratio=(0.7, 0.15, 0.15)):
    """
    Copies images from source_dir → dataset/train|val|test/class_name
    """
    if not source_dir or not os.path.isdir(source_dir):
        print(f" Skipping {class_name}, source folder not found.")
        return

    os.makedirs(f"{base_dir}/train/{class_name}", exist_ok=True)
    os.makedirs(f"{base_dir}/val/{class_name}", exist_ok=True)
    os.makedirs(f"{base_dir}/test/{class_name}", exist_ok=True)

    files = [f for f in os.listdir(source_dir) if os.path.splitext(f)[1].lower() in IMG_EXTS]
    random.shuffle(files)

    n = len(files)
    n_train = int(split_ratio[0] * n)
    n_val = int(split_ratio[1] * n)

    train_files = files[:n_train]
    val_files = files[n_train:n_train + n_val]
    test_files = files[n_train + n_val:]

    for f in train_files:
        shutil.copy(os.path.join(source_dir, f), f"{base_dir}/train/{class_name}/{f}")

    for f in val_files:
        shutil.copy(os.path.join(source_dir, f), f"{base_dir}/val/{class_name}/{f}")

    for f in test_files:
        shutil.copy(os.path.join(source_dir, f), f"{base_dir}/test/{class_name}/{f}")

    print(f" {class_name}: {len(train_files)} train, {len(val_files)} val, {len(test_files)} test images copied.")

print(" Dataset preparation functions ready to use.")

# 1. Acne
prepare_dataset(find_dir_by_keywords("raw/acne", ["acne"]), "Acne")

# 2. Chickenpox (found inside Monkeypox dataset)
prepare_dataset(find_dir_by_keywords("raw/monkeypox", ["chickenpox"]), "Chickenpox")

# 3. Eczema (DermNet)
prepare_dataset(find_dir_by_keywords("raw/dermnet", ["eczema"]), "Eczema")

# 4. Psoriasis (DermNet)
prepare_dataset(find_dir_by_keywords("raw/dermnet", ["psoriasis"]), "Psoriasis")

# 5. Tinea (DermNet → often "Tinea Ringworm Candidiasis")
prepare_dataset(find_dir_by_keywords("raw/dermnet", ["tinea"]), "Tinea")

# 6. Vitiligo (DermNet → folder "Light Diseases and Disorders of Pigmentation")
prepare_dataset(find_dir_by_keywords("raw/dermnet", ["light", "pigmentation"]), "Vitiligo")

# 7. Pityriasis Rosea (DermNet → folder "Exanthems and Drug Eruptions")
prepare_dataset(find_dir_by_keywords("raw/dermnet", ["exanthems"]), "Pityriasis_Rosea")

train_dir = "dataset/train"
val_dir = "dataset/val"
test_dir = "dataset/test"

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam

# Data augmentation for training set
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True,
    width_shift_range=0.1,
    height_shift_range=0.1
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(
    train_dir, target_size=(224, 224), batch_size=32, class_mode='categorical'
)
val_gen = val_datagen.flow_from_directory(
    val_dir, target_size=(224, 224), batch_size=32, class_mode='categorical'
)

base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))
base_model.trainable = False  # freeze base layers

model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dense(train_gen.num_classes, activation='softmax')
])

model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=20
)

import matplotlib.pyplot as plt

# Accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

test_gen = val_datagen.flow_from_directory(
    "dataset/test", target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=False
)

loss, acc = model.evaluate(test_gen)
print(f" Test Accuracy: {acc*100:.2f}%")

# Fine-tune model
base_model.trainable = True
for layer in base_model.layers[:-30]:  # freeze all but last 30 layers
    layer.trainable = False

model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

fine_tune_history = model.fit(train_gen, validation_data=val_gen, epochs=10)

model.save("/content/drive/MyDrive/SKIN DISEASE/SKIN DISEASE_mobilenetv2.keras")

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# Predictions
preds = model.predict(test_gen)
y_pred = np.argmax(preds, axis=1)
y_true = test_gen.classes
labels = list(test_gen.class_indices.keys())

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Report
print("\nClassification Report:\n")
print(classification_report(y_true, y_pred, target_names=labels))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# Define your disease class labels (must match model output order)
class_names = ["Acne", "Chickenpox", "Eczema", "Pityriasis_Rosea", "Psoriasis", "Tinea", "Vitiligo"]

# Compute confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Normalize the confusion matrix to show percentages
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=class_names)
disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)
plt.title("Normalized Confusion Matrix for Skin Disease Detection")
plt.show()

from sklearn.metrics import precision_recall_fscore_support
import matplotlib.pyplot as plt

# Compute per-class metrics
precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=range(len(class_names)))

x = np.arange(len(class_names))
width = 0.25

plt.figure(figsize=(10,6))
plt.bar(x - width, precision, width, label='Precision')
plt.bar(x, recall, width, label='Recall')
plt.bar(x + width, f1, width, label='F1-Score')

plt.xticks(x, class_names, rotation=45)
plt.ylabel('Score')
plt.title('Per-Class Precision, Recall, and F1-Score')
plt.legend()
plt.tight_layout()
plt.show()

model.save("skin_disease_mobilenetv2_finetuned.h5")

# Save the trained and fine-tuned model
model.save("skin_disease_mobilenetv2_finetuned.h5")
print(" Model saved successfully as skin_disease_mobilenetv2_finetuned.h5")

from google.colab import files
files.download("skin_disease_mobilenetv2_finetuned.h5")

plt.savefig("precision_recall_f1_plot.png", dpi=300, bbox_inches='tight')
print(" Plot saved as precision_recall_f1_plot.png")

from google.colab import drive
drive.mount('/content/drive')

model.save('/content/drive/MyDrive/skin_disease_model/mobilenetv2_skin.h5')

from tensorflow.keras.models import load_model

# Load your trained model (no retraining needed)
model = load_model('/content/drive/MyDrive/SKIN DISEASE/skin_disease_mobilenetv2_finetuned.h5')

print(" Model loaded successfully!")

from tensorflow.keras.preprocessing import image
import numpy as np

# Your class names (same order used during training)
class_names = ["Acne", "Chickenpox", "Eczema", "Pityriasis_Rosea", "Psoriasis", "Tinea", "Vitiligo"]

def predict_skin_disease(img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0
    predictions = model.predict(img_array)
    class_idx = np.argmax(predictions[0])
    confidence = predictions[0][class_idx]
    print(f"🩺 Predicted Disease: {class_names[class_idx]} ({confidence*100:.2f}% confidence)")

# Example: change the path below to one of your test images
predict_skin_disease('/content/drive/MyDrive/SKIN DISEASE/test_images/acne1.jpg')

from google.colab import files
uploaded = files.upload()  # Choose a local image file

for filename in uploaded.keys():
    predict_skin_disease(filename)

import os
import pandas as pd

train_dir = "/content/drive/MyDrive/SKIN DISEASE/dataset/train"

class_counts = {cls: len(os.listdir(os.path.join(train_dir, cls))) for cls in os.listdir(train_dir)}
df = pd.DataFrame(list(class_counts.items()), columns=["Class", "Image Count"]).sort_values(by="Image Count", ascending=False)
df

from sklearn.utils.class_weight import compute_class_weight
import numpy as np

# Compute class weights automatically
classes = np.unique(train_gen.classes)
class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_gen.classes)
class_weights = dict(enumerate(class_weights))
print(" Class Weights:", class_weights)

# Retrain or fine-tune again using these weights
history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10,
    class_weight=class_weights
)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_dir = '/content/drive/MyDrive/SKIN DISEASE/dataset/train'
val_dir = '/content/drive/MyDrive/SKIN DISEASE/dataset/val'
test_dir = '/content/drive/MyDrive/SKIN DISEASE/dataset/test'

train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')
val_gen = val_datagen.flow_from_directory(val_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')
test_gen = test_datagen.flow_from_directory(test_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')

from sklearn.utils.class_weight import compute_class_weight
import numpy as np

# Compute class weights automatically based on your training data
classes = np.unique(train_gen.classes)
class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_gen.classes)
class_weights = dict(enumerate(class_weights))

print(" Class Weights Calculated:")
print(class_weights)

from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.models import load_model

# Load your trained model (no retraining needed)
model = load_model('/content/drive/MyDrive/SKIN DISEASE/skin_disease_mobilenetv2_finetuned.h5')

print("Model loaded successfully!")

import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt

class_names = ["Acne", "Chickenpox", "Eczema", "Pityriasis_Rosea",
               "Psoriasis", "Tinea", "Vitiligo"]

from tensorflow.keras.preprocessing import image

def predict_skin_disease(img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0
    predictions = model.predict(img_array)
    class_idx = np.argmax(predictions[0])
    confidence = predictions[0][class_idx]
    print(f"Predicted Disease: {class_names[class_idx]} ({confidence*100:.2f}%)")

predict_skin_disease('/content/drive/MyDrive/SKIN DISEASE/test_images/acne1.jpg')

!ls "/content/drive/MyDrive/SKIN DISEASE"
!ls "/content/drive/MyDrive/SKIN DISEASE/test_images"

from google.colab import files
uploaded = files.upload()  # choose a local image (e.g., acne.jpg)

for filename in uploaded.keys():
    predict_skin_disease(filename)

from google.colab import files
uploaded = files.upload()  # choose a local image (e.g., acne.jpg)

for filename in uploaded.keys():
    predict_skin_disease(filename)

from google.colab import files
uploaded = files.upload()  # choose a local image (e.g., acne.jpg)

for filename in uploaded.keys():
    predict_skin_disease(filename)

from google.colab import files
uploaded = files.upload()  # choose a local image (e.g., acne.jpg)

for filename in uploaded.keys():
    predict_skin_disease(filename)

from google.colab import files
uploaded = files.upload()  # choose a local image (e.g., acne.jpg)

for filename in uploaded.keys():
    predict_skin_disease(filename)

from google.colab import files
uploaded = files.upload()  # choose a local image (e.g., acne.jpg)

for filename in uploaded.keys():
    predict_skin_disease(filename)

from google.colab import files
uploaded = files.upload()  # choose a local image (e.g., acne.jpg)

for filename in uploaded.keys():
    predict_skin_disease(filename)

predict_skin_disease('/content/drive/MyDrive/SKIN DISEASE/dataset/test/Vitiligo/vitiligo-50.jpg')

from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

preds = model.predict(test_gen)
y_pred = np.argmax(preds, axis=1)
y_true = test_gen.classes
labels = list(test_gen.class_indices.keys())

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(7,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix - Skin Disease Detection')
plt.show()

print(classification_report(y_true, y_pred, target_names=labels))

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Image generator for test data
test_datagen = ImageDataGenerator(rescale=1./255)

test_gen = test_datagen.flow_from_directory(
    '/content/drive/MyDrive/SKIN DISEASE/dataset/test',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False  # important for confusion matrix
)

model.save('/content/drive/MyDrive/SKIN DISEASE/final_skin_disease_model.h5')

from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.models import load_model

# Load your trained model (no retraining needed)
model = load_model('/content/drive/MyDrive/SKIN DISEASE/skin_disease_mobilenetv2_finetuned.h5')

print("Model loaded successfully!")

import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

for layer in base_model.layers[-40:]:
    layer.trainable = True

for layer in base_model.layers[-40:]:
    layer.trainable = True

#  Import required libraries
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam

# Step 1: Create the base model
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

#  Step 2: Freeze all base layers for initial training
for layer in base_model.layers:
    layer.trainable = False

#  Step 3: Add your custom classifier head
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
output = Dense(7, activation='softmax')(x)   # 7 classes for 7 skin diseases

model = Model(inputs=base_model.input, outputs=output)

#  Step 4: Compile for initial training
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#  Step 5: Now you can fine-tune specific layers
for layer in base_model.layers[-40:]:
    layer.trainable = True

#Step 6: Recompile with a lower learning rate for fine-tuning
model.compile(optimizer=Adam(learning_rate=1e-5),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_generator,
                    validation_data=val_generator,
                    epochs=10,
                    callbacks=callbacks)

# Import
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

#  Step 1: Create ImageDataGenerators
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2   # 80% training, 20% validation
)

#  Step 2: Create train and validation generators
train_generator = train_datagen.flow_from_directory(
    '/content/dataset',     # <-- replace with your dataset path
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

val_generator = train_datagen.flow_from_directory(
    '/content/dataset',     # same path as above
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

#  Step 3: Callbacks (Early stopping + learning rate reduction)
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

callbacks = [
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)
]

from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive/MyDrive

!ls "/content/drive/MyDrive/skin_disease_dataset"

!ls "/content/drive/MyDrive/SKIN DISEASE"

!ls "/content/drive/MyDrive/SKIN DISEASE/dataset"

# Import the library
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Step 1: Create ImageDataGenerators (no validation split, since folders already exist)
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)

# Step 2: Create data generators for each split
train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/SKIN DISEASE/dataset/train',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    '/content/drive/MyDrive/SKIN DISEASE/dataset/val',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# Optional: test set (for final evaluation later)
test_generator = val_datagen.flow_from_directory(
    '/content/drive/MyDrive/SKIN DISEASE/dataset/test',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

# Step 3: Check class indices to confirm dataset is recognized
print(train_generator.class_indices)

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

callbacks = [
    EarlyStopping(
        monitor='val_loss',        # watch validation loss
        patience=5,                # stop if no improvement after 5 epochs
        restore_best_weights=True  # load best weights when stopping
    ),
    ReduceLROnPlateau(
        monitor='val_loss',        # reduce learning rate if val_loss stagnates
        factor=0.2,
        patience=3,
        verbose=1
    )
]

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=10,
    callbacks=callbacks
)

model.save('/content/drive/MyDrive/SKIN DISEASE/final_skin_disease_model.h5')
print("Model saved successfully!")

test_loss, test_acc = model.evaluate(test_generator)
print(f"Test Accuracy: {test_acc*100:.2f}%  |  Test Loss: {test_loss:.4f}")

model.save('/content/drive/MyDrive/SKIN DISEASE/final_skin_disease_model_v2.h5')

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix, classification_report
import numpy as np, seaborn as sns

Y_pred = model.predict(test_generator)
y_pred = np.argmax(Y_pred, axis=1)

cm = confusion_matrix(test_generator.classes, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=test_generator.class_indices.keys(),
            yticklabels=test_generator.class_indices.keys())
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

print(classification_report(test_generator.classes, y_pred,
                            target_names=test_generator.class_indices.keys()))

model.save('/content/drive/MyDrive/SKIN DISEASE/final_skin_disease_model_v2.h5')

import pickle

with open('/content/drive/MyDrive/SKIN DISEASE/training_history.pkl', 'wb') as f:
    pickle.dump(history.history, f)